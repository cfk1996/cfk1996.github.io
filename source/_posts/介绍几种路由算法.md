---
title: 介绍几种负载均衡算法
date: 2019-10-26 16:00:16
tags:
    - 分布式
    - Java
---

最近在看sofa-rpc的源码，今天把里面涉及到的路由模块中几个算法记录一下。

现在的很多服务都是由集群组成的，集群前会有一个负载均衡服务器来负责选择一个合适的服务器提供服务，让不同的服务器尽可能均衡的处理请求，这里面就涉及到如何作出选择，就产生了很多种负载均衡算法，需要根据项目场景选择一个适合的。

<!--more-->

### 算法接口

```java
// ProviderInfo封装了服务器信息，如服务器url，权重等
ProviderInfo select(List<ProviderInfo> providers)
```

负载均衡算法就是从一个列表（包含了集群所有服务器）中选择出一个合适的服务器

### 轮询算法(Round Robin)

轮询算法是最容易想到的一个算法，当有请求来时，依次发给每个服务器，如果每个服务器的处理能力一样，每个请求花费的时间也差不多，那么这种算法也能够很好的进行负载均衡。

```java
AtomicLong count = new AtomicLong(0);
public ProviderInfo doSelect(List<ProviderInfo> providerInfos) {
    int length = providerInfos.size(); // 服务器总个数
    return providerInfos.get(count.getAndIncrement() % length);
}
```
非常的简单，用一个变量维护请求的总次数，同时利用Atomic类型来支持并发路由。

### 轮询带权重

如果服务器处理能力相同，那么我们用上面轮询就可以很好的解决负载均衡的问题。但是考虑到不同的服务器的处理能力是不一样的，比如有的服务器16g内存，有的服务器32G内存；有的服务器只部署了一个服务，有的服务器与其他服务一起部署等。所以服务器信息里有带上权重信息，负载均衡时需要考虑到服务器的权重。

该算法在sofa-rpc中是不推荐使用的，效率差

```java
AtomicLong sequence = new AtomicLong(0);
public ProviderInfo doSelect(List<ProviderInfo> providerInfos) {
    int length = providerInfos.size(); // 总个数
    int maxWeight = 0; // 最大权重
    int minWeight = Integer.MAX_VALUE; // 最小权重

    final LinkedHashMap<ProviderInfo, IntegerWrapper> invokerToWeightMap = new LinkedHashMap<ProviderInfo, IntegerWrapper>();
    int weightSum = 0;
    // 计算累计权重，最大权重，最小权重
    for (ProviderInfo providerInfo : providerInfos) {
        int weight = getWeight(providerInfo);
        maxWeight = Math.max(maxWeight, weight); // 累计最大权重
        minWeight = Math.min(minWeight, weight); // 累计最小权重
        if (weight > 0) {
            invokerToWeightMap.put(providerInfo, new IntegerWrapper(weight));
            weightSum += weight;
        }
    }
    int currentSequence = sequence.getAndIncrement();
    if (maxWeight > 0 && minWeight < maxWeight) { // 权重不一样
    // 在无权重中，轮询的顺序为123412341234...
    // 但是加入权重后，一轮的个数为总权重
    // 权重高的需要在一轮中多被选择几次
        int mod = currentSequence % weightSum;

// for循环的结果举例：
// 权重为1、2、3、4三个节点，顺序为 1234234344
// 但是可以看出时间复杂度很高，需要遍历maxWeight*服务器数量
        for (int i = 0; i < maxWeight; i++) {
            for (Map.Entry<ProviderInfo, IntegerWrapper> each : invokerToWeightMap.entrySet()) {
                final ProviderInfo k = each.getKey();
                final IntegerWrapper v = each.getValue();
            // 只有当权重值大于0时才会被选中
            // 权重为1、2、3、4三个节点
            // 1234（1）234
            // 第五次的时候，因为（1）的权重不够
            // 所以跳过，从2开始
                if (mod == 0 && v.getValue() > 0) {
                    return k;
                }
                if (v.getValue() > 0) {
                    v.decrement();
                    mod--;
                }
            }
        }
    }
    // 等权重，相当于上一个
    return providerInfos.get(currentSequence % length);
```


### 随机算法

随机算法也可以考虑服务器的权重来进行负载均衡，让权重高的服务器处理更多的请求。但是需要保障随机数产生是合理的（简单的就是Random类）。

```java
public ProviderInfo doSelect(List<ProviderInfo> providerInfos) {
    ProviderInfo providerInfo = null;
    int size = providerInfos.size();
    int totalWeight = 0; // 总权重
    boolean isWeightSame = true; // 判断权重是否都一样
    for (int i = 0; i < size; i++) {
        int weight = getWeight(providerInfos.get(i));//获取服务器的权重
        totalWeight += weight; // 累计总权重
        if (isWeightSame && i > 0 && weight != getWeight(providerInfos.ge(i - 1))) {
            isWeightSame = false; // 计算所有权重是否一样
        }
    }

    if (totalWeight > 0 && !isWeightSame) {
        // 如果权重不相同且权重大于0则按总权重数随机
        int offset = random.nextInt(totalWeight);
        // 并确定随机值落在哪个片断上
        for (int i = 0; i < size; i++) {
            offset -= getWeight(providerInfos.get(i));
            if (offset < 0) {
                providerInfo = providerInfos.get(i);
                break;
            }
        }
// 举个例子方便理解，假设就两个服务器，第一个权重1，第二个权重2
// 则totalWeigh=1+2=3
// random.nextInt(totalWeight)会均衡的产生0,1,2三个数字
// 如果产生0则第一次循环时offset = 0-1 = -1 < 0
// 所以选择第一个服务器
// 如果产生1则第一次循环时offset = 1-1 = 0;
// 因为不小于0,进入第二次循环，选择第二个机器
// 如果产生2则也是同样的选择第二个机器
// 因为0,1,2产生的概率相等，但是出现1和2时都是第二台服务器
// 所以第二台服务器处理的请求大概是第一台的两倍
// 与它们的权重是1和2一致
    } else {
        // 如果权重相同或权重为0则均等随机
        providerInfo = providerInfos.get(random.nextInt(size));
    }
    return providerInfo;
}
```

### 一致性哈希算法

上面的两种负载均衡算法，在无状态的集群中可以表现的不错，但很多服务是有状态的，比如同一个用户的多个请求，希望始终发到同一个机器来处理，所以又产生了一致性哈希负载均衡算法。

假设有3台服务器，计算出的hash值为100，500， 10000.另外假设计算出来的hash上限为15000.那么就可以想象出一个环，起点为0，终点为15000，顺时针慢慢变大。
```shell
    0 -->100----->200
    |               |
    |               |
    10000<-----------  
```

当请求来时，会根据请求的参数也计算出一个hash值，如果落在0～100，则让第一台服务器处理，落在100～200让第二台服务器处理依次类推。但是可以从图里看出个缺陷，就是hash值是我们无法控制的，会导致不同服务器之间的`hash间距`差异很大，导致不均衡，下面看下`sofa-rpc`如何解决这个问题。


```java
// 同一个方法名字的会发送到同一个服务器
// SofaRequest封装了请求相关信息 
Selector selector = null;
public ProviderInfo doSelect(SofaRequest request, List<ProviderInfo> providerInfos) {
    String interfaceId = request.getInterfaceName();
    String method = request.getMethodName();
    int hashcode = providerInfos.hashCode(); // 判断是否同样的服务列表
    if (selector == null // 原来没有
        ||
        selector.getHashCode() != hashcode) { // 或者服务列表已经变化
        selector = new Selector(interfaceId, method, providerInfos, hashcode);
    }
    return selector.select(request);
}
```

因为要计算服务器的hash值,添加一个新的Selector变量,避免hash值重复计算
```java
public Selector(String interfaceId, String method, List<ProviderInfo> actualNodes, int hashcode) {
    this.interfaceId = interfaceId;
    this.method = method;
    this.hashcode = hashcode;
// 常规一致性hash算法一个服务器只有一个节点
// 但是由于hash值无法控制，会导致不同服务器间hash值距离差距过大
// 导致不均衡
// sofa-rpc中进行了优化
// 创建虚拟节点环 （默认一个provider共创建128个虚拟节点，较多比较均匀）
// 所有虚拟节点用TreeMap保存，TreeMap按hash值有序
    this.virtualNodes = new TreeMap<Long, ProviderInfo>();
    int num = 128;
    for (ProviderInfo providerInfo : actualNodes) {
        for (int i = 0; i < num / 4; i++) {
            byte[] digest = HashUtils.messageDigest(providerInfo.getHost() + providerInfo.getPort() + i);
            for (int h = 0; h < 4; h++) {
                long m = HashUtils.hash(digest, h);
                virtualNodes.put(m, providerInfo);
            }
        }
    }
}

// selector.select()
public ProviderInfo select(SofaRequest request) {
    // 获取方法名字符串
    String key = buildKeyOfHash(request.getMethodArgs());
    // 计算该方法的hash值，相同的方法hash一样
    byte[] digest = HashUtils.messageDigest(key);
    return selectForKey(HashUtils.hash(digest, 0));
}
private ProviderInfo selectForKey(long hash) {
// TreeMap.ceilingEntry获取大于hash的第一个元素
    Map.Entry<Long, ProviderInfo> entry = virtualNodes.ceilingEntry(hash);
    if (entry == null) {
    // 如果没有，则是从头开始的第一个元素，所以像个环
        entry = virtualNodes.firstEntry();
    }
    return entry.getValue();
}
```

### 一致性哈希带权重

上面那个算法没有考虑权重的因素，考虑权重也很简单。在`Seletor`的构造函数中，我们固定为每个服务器创建128个节点，如果考虑权重，只需要在创建虚拟节点时，将创建的个数乘以权重系数，这样不同权重的服务器产生的虚拟节点个数与权重成正比。其他代码不需改动。

```java
public Selector(String interfaceId, String method, List<ProviderInfo> actualNodes, int hashcode) {
    ...
    // 创建虚拟节点环 （provider创建虚拟节点数 =  真实节点权重 * 32）
    this.virtualNodes = new TreeMap<Long, ProviderInfo>();
    // 设置越大越慢，精度越高
    int num = 32;
    for (ProviderInfo providerInfo : actualNodes) {
        // 只需要修改一行代码，i < num * providerInfo.getWeight()
        for (int i = 0; i < num * providerInfo.getWeight() / 4; i++) {
            byte[] digest = HashUtils.messageDigest(providerInfo.getHost() + providerInfo.getPort() + i);
            for (int h = 0; h < 4; h++) {
                long m = HashUtils.hash(digest, h);
                virtualNodes.put(m, providerInfo);
            }
        }
    }
}
```

### 其他废话

有段时间没写博客了，几个礼拜前想写`阻塞队列SynchronizedQueue源码分析`，我一直是边看边写的，写了一大半，有些关键的代码看不懂了，所以停止了那篇文章。同步、并发相关的代码理解难度比较大，我现在水平还不够，不能很好的理解，就不写出来误导大家，继续修炼～

以后可能会更关注高层次一些的东西，比如框架源码，一些算法思想什么的。至于并发底层的文章，需要再积累一段时间。

### 往期回顾

* [Java动态代理原理剖析(一)](https://cfk1996.github.io/2019/02/28/Java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/)

* [Java线程池源码](https://cfk1996.github.io/2019/05/02/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)

### 欢迎关注我的公众号

欢迎关注我的公众号，会经常分享一些技术文章和生活随笔～

![技术旅途](https://raw.githubusercontent.com/cfk1996/cfk1996.github.io/source/photos/wechat.jpg)